\documentclass{scrartcl}% siehe <http://www.komascript.de>
\usepackage[margin=2.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}

\newtheorem{theorem}{Lemma}

\newcommand{\includepic}[2]{\includegraphics[width=#2\textwidth,height=#2\textheight,keepaspectratio]{#1}}

\usepackage[yyyymmdd,hhmm]{datetime}

% Base path of images
\usepackage{graphicx}
\graphicspath{ {../lectures-img/} }

\begin{document}
    % ----------------------------------------------------------------------------
    \subject{Vorlesungsmitschrieb}
    \title{Algorithmen und Berechenbarkeit}
    \subtitle{Vorlesung 01}
    \date{Letztes Update: \today \ - \currenttime \ Uhr}
    \maketitle
    % ----------------------------------------------------------------------------
    \section*{Organisatorisches}
    \label{sec:organisatorisches}

    \subsection*{Übung}
    \label{subsec:übung}

    \begin{itemize}
        \item Anmeldung über das Campus
        \item Übungsabwicklung über Ilias
        \item 14 -tägig
        \item Anmeldung zwischen 10/20/2017 - 10/27/2017 ab 16 Uhr
        \item Gruppengröße: 3-4 Personen
        \item Mehr Informationen auf der Website
    \end{itemize}

    \subsection*{Schein}
    \label{subsec:schein}

    \begin{itemize}
        \item 50\% der Punkte aus den Übungen
        \item Mindestens 50\% der Aufgaben votieren
        \item Bestehen von 2 MC-Tests
    \end{itemize}

    Pro Übungsblatt wird in der Regel eine Woche Bearbeitungszeit eingeräumt.
    Wer Aufgaben abgibt, "`votiert"' automatsich für diese Aufgaben.
    Falls die Aufgaben im Zweifel unzureichend vorgerechnet werden,
    gibt es 0 Punkte für das gesamte Blatt.

    \section*{Randomisierte Algorithmen}
    \label{sec:randomisierteAlgorithmen}

    Randomisierte Algorithmen sind Algorithmen,
    welche unter Nutzung einer Zufallsquelle (z.B. Münzwurf, Zufallsgenerator) Probleme lösen.
    In manchen Fällen sind diese Algorithmen einfacher und effizienter
    als die entsprechenden deterministischen Algorithmen.

    Randomisierte Algorithmen werden nach "`dem Verbrauch von Zufall"' bewertet,
    denn Zufall zu erzeugen, ist nicht so ohne Weiteres möglich (Zufall zu "`erzeugen"' ist \textbf{teuer}).
    Im Gegensatz dazu bewertet man "`normale"' Algorithmen nach Platz- und Zeitbedarf.

    Wir haben bisher die folgenden Gattungen kennengelernt:

    \begin{itemize}
        \item \textbf{\textsf{Las-Vegas:}} Die Laufzeit hängt vom Zufall ab, die Korrektheit nicht.
        \item \textbf{\textsf{Monte-Carlo:}} Die Laufzeit hängt nicht vom Zufall ab, die Korrektheit schon.
    \end{itemize}

    \subsection*{Closest Pair (Randomisiert, Las-Vegas)}
    \label{subsec:closestPairrandomisiert,LasVegas}

    Gegeben seien $n$ Punkte im $\mathbb{R}^2$

    \begin{figure}[htb]
        \centering
        \includepic{lec_01_a}{0.25}
        \label{fig:CP_a}
    \end{figure}

    \textbf{\textsf{Ziel:}} Finde das Paar mit dem kleinsten Abstand zueinander.

    \subsubsection*{Naiver Ansatz}
    \label{subsec:naiveransatz}

    \begin{itemize}
        \item Betrachte $P_1$ und berechne Distanzen zu $P_2, P_3, ..., P_n$
        \item Betrachte $P_2$ und berechne Distanzen zu $P_3, P_4, ..., P_n$
    \end{itemize}

    Das würde eine Laufzeit von

    \begin{equation*}
        O\left(\sum_{i=1}^{n-1}\right) = O\left( \frac{(n-1) \cdot n}{2} \right) = O(n^2)
    \end{equation*}

    ergeben.
    Ein Prozessor mit 1 GHz Taktfrequenz schafft
    1.000.000 Instruktionen pro Sekunde.
    Das führt zu folgender Tabelle:
    \begin{table}[!ht]
        \centering
        \begin{tabular}{llll}
            \textbf{\textsf{n}} & \textbf{\textsf{Rechnung}} & & \textbf{\textsf{Ergebnis}}\\
            \hline
            $=100       $ & $100^2 \cdot 10^{-9}$       & $=10^{-5}$   & 10 $\mu$s \\
            $=1000      $ & $1000^2 \cdot 10^{-9}$      & $10^{-3}$    & 1 ms \\
            $=10000     $ & $10000^2 \cdot 10^{-9}$     & $10$         & 10 s \\
            $=1000000   $ & $1000000^2 \cdot 10^{-9}$   & $10^3$       & 15 min \\
            \hline \\
        \end{tabular}
    \end{table}
    $O(n^2)$ ist für das Problem nicht praktikabel.

    \subsubsection*{Randomisierter Algorithmus für CP}
    \label{subsec:randomisierterAlgorithmusfürCP}

    Ein randomisierter Algorithmus mit \textit{erwarteter Laufzeit}
    (Varianten: Glück & Pech) hat eine Laufzeit von $O(n)$.
    Er wird aus folgendem inkrementellen Ansatz hergeleitet:

    Zuerst wird die Datenmenge $P = \{ P_1, P_2, P_3, ..., P_n \}$ betrachtet.
    Sei nun $\delta_i$ die CP-Distanz in der Menge $P$.
    Es kommt nun ein weiterer Punkt $P_{i+1}$ hinzu.

    Eine einfache Möglichkeit, den neuen geringsten Abstand zu finden, wäre,
    wenn man die Abstände vom neuen Punkt zu allen anderen Punkten vergleicht und überprüft,
    ob es einen kleineren Abstand als das bisherige $\delta_i$ gibt.

    Besser wäre jedoch Folgendes: Angenommen, $\delta_i$ ist bestimmt.
    So kann nun ein Gitter erzeugt werden, das eine Maschenweite
    (Breite der Zeilen/Spalten) von genau $\delta_i$ hat.

    \begin{figure}[h]
        \centering
        \includepic{lec_01_b}{0.35}
        \label{fig:CP_b}
    \end{figure}

    \newpage
    Das Einfügen folgt einem einfachen Ablauf

    \begin{enumerate}
        \item Lokalisiere $P_{i+1}$ im Gitter (orange)
        \item Inspiziere alle Punkte im Feld von $P_{i+1}$ sowie alle Felder um $P_{i+1}$ herum (gelb)
        \begin{enumerate}
            \item $\delta_{i+1} = \delta_i \rightarrow$ Nichts mehr tun $\rightarrow O(1)$
            \item $\delta_{i+1} < \delta_i \rightarrow$ Baue Gitter mit neuer Maschenweite
            $\delta_{i+1}$ $\rightarrow O(n^2)$ im schlimmsten Fall
        \end{enumerate}
    \end{enumerate}

    Da es auch Fälle geben kann, in denen $P_{i+1}$ immer einen kleineres $\delta$ hat als davor
    (Liste nach größtem Abstand geordnet), empfiehlt es sich, die Punkte immer in zufälliger Reihenfolge "`einzufügen"'.
    So bleibt eine Wahrscheinlichkeit von $\frac{2}{i+1}$ dafür, dass der nächste Punkt ein CP-Punkt ist.

    Die erwarteten Kosten des Einfügens sind

    \begin{equation*}
        \leq \underbrace{\frac{2}{i+1} \cdot O(n)}_{schlechter Fall} + \underbrace{O(1)}_{guter Fall} = O(1) + O(1) = O(1)
    \end{equation*}

    Damit lässt sich der Erwartungswert berechnen zu

    \begin{equation*}
        E\left[ \sum^{n}_{i=1}(Kosten\ für\ Einfügen\ von\ P_i)\right] = \sum^{n}_{i=1}E[Kosten\ für\ Einfügen\ von\ P_i] \\
        = \sum^{n}_{i=1}O(1) = O(n)
    \end{equation*}

    \begin{theorem}
        Die Wahrscheinlichkeit, beim Einfügen von $P_{i+1}$ das Gitter neu aufbauen zu müssen, ist $< \frac{2}{i+1}$.
    \end{theorem}

    \begin{proof}[\textbf{Beweis}]
        Das Gitter muss genau dann neu aufgebaut werden, wenn $P_{i+1}$
        einer der beiden Punkte ist, welche das CP in der Menge der ersten $i+1$ Punkte bestimmen.
        Jeder der ersten $i+1$ Punkte ist mit gleicher Wahrscheinlichkeit der $P_{i+1}$.

        Falls CP eindeutig:
        \begin{equation*}
            \rightarrow P(Gitter\ muss\ neu\ aufgebaut\ werden) = \frac{2}{i}
        \end{equation*}

        \textbf{\textsf{Wichtig:}} Wenn der Algorithmus länger braucht, hat das nichts mit der Eingabe zu tun.
        Der randomisierte Closest-Pair-Algorithmus berechnet immer ein korrektes Resultat.

    \end{proof}

    \subsubsection*{Closest Pair mit deterministischem Algorithmus}
    \label{subsec:closestPairmitdeterministischemAlgorithmus}
    Closest Pair kann in $O(n \cdot \log(n))$ berechnet werden.
    Es kann sogar gezeigt werden, dass CP mindestens $\Omega(n \cdot \log(n))$ braucht.

    Deterministisch geht CP vergleichsbasiert nicht besser aks $\Omega(n \cdot \log(n))$

    \begin{table}[!ht]
        \centering
        \begin{tabular}{llll}
            \textbf{\textsf{n}} & \textbf{\textsf{Rechnung}} & \textbf{\textsf{Ergebnis}}\\
            \hline \\
            $=1000000   $ & $10^6 \cdot 6 \cdot  10^{-9}$   & 6 ms \\
            \hline \\
        \end{tabular}
    \end{table}

    \begin{proof}[\textbf{Beweis}]
        Man weiß, dass Elementuniqueness (geg $n$ Zahlen; entscheide, ob eine Zahl doppelt vorkommt)
        $\Omega(n \cdot \log(n))$ braucht.
        Falls CP deterministisch vergleichsbasiert besser als $o(n \cdot \log(n))$
        gelöst werden könnte, so könnte man auch Elementuniqueness in dieser Zeit lösen
        (Zahl $i \rightarrow Punkt \ (i, i) \in \mathbb{R}^2$). Allerdings gilt das nur in einem
        anderem Rechenmodell (Randomisierung und Abrundung).

    \end{proof}

    \hrulefill

    \section*{Anhang}
    \label{sec:anhang}

    \subsubsection*{Zufallsvariable und Erwartungswert}
    \label{sec:zufallsvariableUndErwartungswert}
    Sei $Y$ eine Zufallsvariable, zum Beispiel \textit{Augenzahl beim Wurf} mit einem normalen und fairen Würfel. \newline
    Der Erwartungswert berechnet sich zu

    \begin{equation*}
        E[X] = \sum Ereignis \cdot P(Ereignis)
    \end{equation*}

    Für $Y$ also: $\frac{1}{6} \cdot 1 + \frac{1}{6} \cdot 2 + \frac{1}{6} \cdot 3 +
    \frac{1}{6} \cdot 4 + \frac{1}{6} \cdot 5 + \frac{1}{6} \cdot 6  = 3,5$

\end{document}